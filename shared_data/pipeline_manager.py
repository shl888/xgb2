"""
PipelineManager æ™ºèƒ½ç‰ˆ - å®Œæ•´å®ç°
åŒ…å«ï¼šæ‰¹é‡å¤„ç† + å†…å­˜ç›‘æ§ + Step4ç¼“å­˜ç›‘æ§
"""

import asyncio
from enum import Enum
from typing import Dict, Any, Optional, Callable
import logging
import time
from dataclasses import dataclass

# 5ä¸ªæ­¥éª¤ + å†…å­˜ç›‘æ§
from shared_data.step1_filter import Step1Filter
from shared_data.step2_fusion import Step2Fusion
from shared_data.step3_align import Step3Align
from shared_data.step4_calc import Step4Calc
from shared_data.step5_cross_calc import Step5CrossCalc

try:
    import psutil  # å¯é€‰ä¾èµ–ï¼Œç”¨äºå†…å­˜ç›‘æ§
except ImportError:
    psutil = None

logger = logging.getLogger(__name__)

class DataType(Enum):
    MARKET = "market"
    ACCOUNT = "account"

@dataclass
class PipelineConfig:
    """æ™ºèƒ½ç‰ˆé…ç½®"""
    queue_max_size: int = 5000           # ä¸Šé™5000ï¼ˆçº¦300MBï¼‰
    processing_timeout: float = 1.0
    batch_size: int = 10
    log_interval: int = 60
    memory_safe_threshold: float = 70.0  # å†…å­˜å®‰å…¨é˜ˆå€¼70%

class PipelineManager:
    """æ™ºèƒ½ç‰ˆ - å®Œæ•´å®ç°"""
    
    _instance: Optional['PipelineManager'] = None
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    @classmethod
    def instance(cls) -> 'PipelineManager':
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    def __init__(self, brain_callback: Optional[Callable] = None, 
                 config: Optional[PipelineConfig] = None):
        
        if hasattr(self, '_initialized') and self._initialized:
            return
        
        self.config = config or PipelineConfig()
        self.brain_callback = brain_callback
        
        # 5ä¸ªæ­¥éª¤
        self.step1 = Step1Filter()
        self.step2 = Step2Fusion()
        self.step3 = Step3Align()
        self.step4 = Step4Calc()
        self.step5 = Step5CrossCalc()
        
        self.processing_lock = asyncio.Lock()
        
        self.counters = {
            'market_processed': 0,
            'account_processed': 0,
            'errors': 0,
            'batches_processed': 0,
            'dropped_due_to_memory': 0,
            'start_time': time.time()
        }
        
        self.running = False
        self.queue = asyncio.Queue(maxsize=self.config.queue_max_size)
        self._step1_buffer: List[Any] = []
        
        logger.info(f"âœ… æ™ºèƒ½ç‰ˆPipelineManageråˆå§‹åŒ–å®Œæˆ (é˜Ÿåˆ—ä¸Šé™: {self.config.queue_max_size})")
        self._initialized = True
    
    def _get_memory_usage_percent(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨ç‡"""
        if psutil is None:
            return 0.0
        try:
            return psutil.virtual_memory().percent
        except:
            return 0.0
    
    def _is_memory_safe(self) -> bool:
        """æ£€æŸ¥å†…å­˜æ˜¯å¦å®‰å…¨"""
        usage = self._get_memory_usage_percent()
        return usage < self.config.memory_safe_threshold
    
    async def start(self):
        """å¯åŠ¨æ‰€æœ‰åå°ä»»åŠ¡"""
        if self.running:
            return
        
        logger.info("ğŸš€ æ™ºèƒ½ç‰ˆPipelineManagerå¯åŠ¨...")
        self.running = True
        
        # âœ… å¯åŠ¨3ä¸ªåå°ä»»åŠ¡
        asyncio.create_task(self._consumer_loop())
        asyncio.create_task(self._memory_monitor_loop())
        asyncio.create_task(self._periodic_log_loop())
        
        logger.info("âœ… æ¶ˆè´¹è€…å¾ªç¯ + ç›‘æ§ä»»åŠ¡å·²å¯åŠ¨")
    
    async def stop(self):
        """ä¼˜é›…åœæ­¢"""
        logger.info("ğŸ›‘ PipelineManageråœæ­¢ä¸­...")
        self.running = False
        
        await asyncio.sleep(1)
        
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except:
                break
        
        logger.info("âœ… PipelineManagerå·²åœæ­¢")
    
    async def ingest_data(self, data: Dict[str, Any]) -> bool:
        """æ™ºèƒ½å…¥é˜Ÿï¼ˆå¸¦å†…å­˜æ„ŸçŸ¥ï¼‰"""
        try:
            # åˆ†ç±»
            data_type = data.get("data_type", "")
            if data_type.startswith(("ticker", "funding_rate", "mark_price",
                                   "okx_", "binance_")):
                category = DataType.MARKET
            elif data_type.startswith(("account", "position", "order", "trade")):
                category = DataType.ACCOUNT
            else:
                category = DataType.MARKET
            
            queue_item = {
                "category": category,
                "data": data,
                "timestamp": time.time()
            }
            
            # å°è¯•ç›´æ¥å…¥é˜Ÿ
            try:
                self.queue.put_nowait(queue_item)
                return True
            except asyncio.QueueFull:
                pass
            
            # å†…å­˜æ£€æŸ¥
            if not self._is_memory_safe():
                logger.warning(f"âš ï¸ å†…å­˜å±é™©({self._get_memory_usage_percent():.1f}%)ï¼Œæ‹’ç»æ•°æ®")
                self.counters['dropped_due_to_memory'] += 1
                return False
            
            # ä¸¢å¼ƒè€æ•°æ®åå…¥é˜Ÿ
            try:
                self.queue.get_nowait()  # ä¸¢å¼ƒæœ€è€ä¸€æ¡
                self.queue.put_nowait(queue_item)
                logger.debug(f"ğŸ”„ é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒè€æ•°æ®åå…¥é˜Ÿ: {data.get('symbol', 'N/A')}")
                return True
            except:
                return False
            
        except Exception as e:
            logger.error(f"å…¥é˜Ÿå¤±è´¥: {e}")
            return False
    
    async def _consumer_loop(self):
        """æ ¸å¿ƒæ¶ˆè´¹è€…å¾ªç¯"""
        logger.info("ğŸ”„ æ¶ˆè´¹è€…å¾ªç¯å¯åŠ¨ï¼ˆæ‰¹é‡å¤„ç† + å†…å­˜æ„ŸçŸ¥ï¼‰...")
        
        while self.running:
            try:
                queue_item = await asyncio.wait_for(
                    self.queue.get(), 
                    timeout=self.config.processing_timeout
                )
                await self._process_single_item(queue_item)
                self.queue.task_done()
                
            except asyncio.TimeoutError:
                if len(self._step1_buffer) > 0:
                    await self._flush_buffer()
                continue
            except Exception as e:
                logger.error(f"å¾ªç¯å¼‚å¸¸: {e}")
                self.counters['errors'] += 1
                await asyncio.sleep(0.1)
    
    async def _process_single_item(self, item: Dict[str, Any]):
        """å•æ¡æ•°æ®å¤„ç†"""
        category = item["category"]
        raw_data = item["data"]
        
        async with self.processing_lock:
            try:
                if category == DataType.MARKET:
                    self._step1_buffer.append(raw_data)
                    
                    if len(self._step1_buffer) >= self.config.batch_size:
                        await self._flush_buffer()
                    
                elif category == DataType.ACCOUNT:
                    await self._process_account_data(raw_data)
                
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥: {raw_data.get('symbol', 'N/A')} - {e}")
                self.counters['errors'] += 1
    
    async def _flush_buffer(self):
        """æ‰¹é‡åˆ·æ–°ç¼“å†²åŒº"""
        if not self._step1_buffer:
            return
        
        try:
            logger.debug(f"æ‰¹é‡å¤„ç† {len(self._step1_buffer)} æ¡æ•°æ®...")
            
            step1_results = self.step1.process(self._step1_buffer)
            self._step1_buffer.clear()
            
            if not step1_results:
                return
            
            step2_results = self.step2.process(step1_results)
            if not step2_results:
                return
            
            step3_results = self.step3.process(step2_results)
            if not step3_results:
                return
            
            step4_results = self.step4.process(step3_results)
            if not step4_results:
                return
            
            final_results = self.step5.process(step4_results)
            if not final_results:
                return
            
            if self.brain_callback:
                for result in final_results:
                    await self.brain_callback(result.__dict__)
            
            self.counters['batches_processed'] += 1
            self.counters['market_processed'] += len(final_results)
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            self.counters['errors'] += 1
    
    async def _process_account_data(self, data: Dict[str, Any]):
        """è´¦æˆ·æ•°æ®ç›´è¿å¤§è„‘"""
        if self.brain_callback:
            await self.brain_callback(data)
        
        self.counters['account_processed'] += 1
        logger.debug(f"ğŸ’° è´¦æˆ·æ•°æ®ç›´è¾¾: {data.get('exchange', 'N/A')}")
    
    async def _memory_monitor_loop(self):
        """å†…å­˜ç›‘æ§å¾ªç¯ï¼ˆæ¯10ç§’ï¼‰"""
        while self.running:
            try:
                await asyncio.sleep(10)
                
                mem_usage = self._get_memory_usage_percent()
                queue_size = self.queue.qsize()
                
                if mem_usage > self.config.memory_safe_threshold:
                    logger.warning(f"âš ï¸ å†…å­˜å‹åŠ›é«˜: {mem_usage:.1f}% | é˜Ÿåˆ—: {queue_size}")
                
                if queue_size > self.config.queue_max_size * 0.8:
                    logger.warning(f"âš ï¸ é˜Ÿåˆ—å †ç§¯: {queue_size}/{self.config.queue_max_size}")
                
            except Exception as e:
                logger.error(f"å†…å­˜ç›‘æ§å¼‚å¸¸: {e}")
    
    async def _periodic_log_loop(self):
        """å®šæœŸæ—¥å¿—å¾ªç¯"""
        while self.running:
            try:
                await asyncio.sleep(self.config.log_interval)
                
                status = self.get_status()
                logger.info("="*60)
                logger.info(f"ğŸ“Š æµæ°´çº¿è¿è¡ŒæŠ¥å‘Šï¼ˆè¿è¡Œ: {int(status['uptime_seconds'])}ç§’ï¼‰")
                logger.info(f"å¤„ç†é‡: å¸‚åœº={status['market_processed']} | è´¦æˆ·={status['account_processed']}")
                logger.info(f"æ‰¹é‡æ•°: {status['batches_processed']} | é”™è¯¯: {status['errors']}")
                logger.info(f"é˜Ÿåˆ—: {status['queue_size']}/{self.config.queue_max_size} | å†…å­˜: {status['memory_usage_percent']:.1f}%")
                logger.info("="*60)
                
            except Exception as e:
                logger.error(f"æ—¥å¿—å¾ªç¯å¼‚å¸¸: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´çŠ¶æ€"""
        uptime = time.time() - self.counters['start_time']
        mem_usage = self._get_memory_usage_percent()
        return {
            "running": self.running,
            "uptime_seconds": uptime,
            "market_processed": self.counters['market_processed'],
            "account_processed": self.counters['account_processed'],
            "batches_processed": self.counters['batches_processed'],
            "errors": self.counters['errors'],
            "queue_size": self.queue.qsize(),
            "buffer_size": len(self._step1_buffer),
            "memory_usage_percent": mem_usage,
            "dropped_due_to_memory": self.counters['dropped_due_to_memory'],
            "memory_safe": self._is_memory_safe()
        }
