"""
PipelineManager æ™ºèƒ½ç‰ˆ - åŠ¨æ€é˜Ÿåˆ— + å†…å­˜æ„ŸçŸ¥
åŠŸèƒ½ï¼šè‡ªåŠ¨å¹³è¡¡å†…å­˜ä¸ååé‡
"""

import asyncio
from enum import Enum
from typing import Dict, Any, List, Optional, Callable
from datetime import datetime
import logging
import time
from dataclasses import dataclass

# å¯¼å…¥å†…å­˜ç›‘æ§
import psutil  # éœ€è¦ pip install psutil

# 5ä¸ªæ­¥éª¤
from shared_data.step1_filter import Step1Filter
from shared_data.step2_fusion import Step2Fusion
from shared_data.step3_align import Step3Align
from shared_data.step4_calc import Step4Calc
from shared_data.step5_cross_calc import Step5CrossCalc

logger = logging.getLogger(__name__)

class DataType(Enum):
    MARKET = "market"
    ACCOUNT = "account"

@dataclass
class PipelineConfig:
    """æ™ºèƒ½ç‰ˆé…ç½®"""
    queue_max_size: int = 5000           # âœ… ä¸Šé™5000ï¼ˆçº¦300MBï¼‰
    processing_timeout: float = 1.0
    batch_size: int = 10
    log_interval: int = 60
    memory_safe_threshold: float = 70.0  # âœ… æ–°å¢ï¼šå†…å­˜å®‰å…¨é˜ˆå€¼70%

class PipelineManager:
    """æ™ºèƒ½ç‰ˆ - å†…å­˜æ„ŸçŸ¥ + åŠ¨æ€é˜Ÿåˆ—"""
    
    _instance: Optional['PipelineManager'] = None
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    @classmethod
    def instance(cls) -> 'PipelineManager':
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    def __init__(self, brain_callback: Optional[Callable] = None, 
                 config: Optional[PipelineConfig] = None):
        
        if hasattr(self, '_initialized') and self._initialized:
            return
        
        self.config = config or PipelineConfig()
        self.brain_callback = brain_callback
        
        # 5ä¸ªæ­¥éª¤
        self.step1 = Step1Filter()
        self.step2 = Step2Fusion()
        self.step3 = Step3Align()
        self.step4 = Step4Calc()
        self.step5 = Step5CrossCalc()
        
        self.processing_lock = asyncio.Lock()
        
        self.counters = {
            'market_processed': 0,
            'account_processed': 0,
            'errors': 0,
            'batches_processed': 0,
            'dropped_due_to_memory': 0,  # âœ… æ–°å¢ï¼šå› å†…å­˜ä¸¢å¼ƒè®¡æ•°
            'start_time': time.time()
        }
        
        self.running = False
        self.queue = asyncio.Queue(maxsize=self.config.queue_max_size)
        self._step1_buffer: List[Any] = []
        
        logger.info(f"âœ… æ™ºèƒ½ç‰ˆPipelineManageråˆå§‹åŒ–å®Œæˆ (åŠ¨æ€é˜Ÿåˆ—: {self.config.queue_max_size})")
        self._initialized = True
    
    def _get_memory_usage_percent(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨ç‡"""
        try:
            return psutil.virtual_memory().percent
        except:
            return 0.0
    
    def _is_memory_safe(self) -> bool:
        """æ£€æŸ¥å†…å­˜æ˜¯å¦å®‰å…¨"""
        usage = self._get_memory_usage_percent()
        return usage < self.config.memory_safe_threshold
    
    async def start(self):
        if self.running:
            return
        
        logger.info("ğŸš€ æ™ºèƒ½ç‰ˆPipelineManagerå¯åŠ¨...")
        self.running = True
        
        asyncio.create_task(self._consumer_loop())
        asyncio.create_task(self._cache_monitor_loop())
        asyncio.create_task(self._memory_monitor_loop())  # âœ… æ–°å¢ï¼šå†…å­˜ç›‘æ§
        
        logger.info("âœ… æ¶ˆè´¹è€…å¾ªç¯å·²å¯åŠ¨")
    
    async def stop(self):
        logger.info("ğŸ›‘ PipelineManageråœæ­¢ä¸­...")
        self.running = False
        
        await asyncio.sleep(1)
        
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except:
                break
        
        logger.info("âœ… PipelineManagerå·²åœæ­¢")
    
    async def ingest_data(self, data: Dict[str, Any]) -> bool:
        """
        æ™ºèƒ½å…¥é˜Ÿï¼š
        - é˜Ÿåˆ—æœªæ»¡ï¼šç›´æ¥å…¥é˜Ÿ
        - é˜Ÿåˆ—æ»¡äº†ä½†å†…å­˜å®‰å…¨ï¼šæ‰©å®¹å…¥é˜Ÿï¼ˆä¸¢å¼ƒæœ€è€æ•°æ®ï¼‰
        - é˜Ÿåˆ—æ»¡äº†ä¸”å†…å­˜å±é™©ï¼šæ‹’ç»å…¥é˜Ÿ
        """
        try:
            # 1. å¿«é€Ÿåˆ†ç±»
            data_type = data.get("data_type", "")
            if data_type.startswith(("ticker", "funding_rate", "mark_price",
                                   "okx_", "binance_")):
                category = DataType.MARKET
            elif data_type.startswith(("account", "position", "order", "trade")):
                category = DataType.ACCOUNT
            else:
                category = DataType.MARKET
            
            queue_item = {
                "category": category,
                "data": data,
                "timestamp": time.time()
            }
            
            # 2. å°è¯•ç›´æ¥å…¥é˜Ÿ
            try:
                self.queue.put_nowait(queue_item)
                return True
            except asyncio.QueueFull:
                pass  # é˜Ÿåˆ—æ»¡äº†ï¼Œè¿›å…¥æ™ºèƒ½å¤„ç†
            
            # 3. å†…å­˜æ£€æŸ¥
            if not self._is_memory_safe():
                logger.warning(f"âš ï¸ å†…å­˜å±é™©({self._get_memory_usage_percent():.1f}%)ï¼Œæ‹’ç»æ•°æ®")
                self.counters['dropped_due_to_memory'] += 1
                return False
            
            # 4. é˜Ÿåˆ—æ»¡ä½†å†…å­˜å®‰å…¨ï¼šå°è¯•ä¸¢å¼ƒæœ€è€çš„æ•°æ®ï¼Œç„¶åå…¥é˜Ÿ
            try:
                # ä¸¢å¼ƒæœ€è€çš„ä¸€æ¡
                self.queue.get_nowait()
                self.queue.put_nowait(queue_item)
                logger.debug(f"ğŸ”„ é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒè€æ•°æ®åå…¥é˜Ÿ: {data.get('symbol', 'N/A')}")
                return True
            except:
                return False  # è¿˜æ˜¯å¤±è´¥
            
        except Exception as e:
            logger.error(f"å…¥é˜Ÿå¤±è´¥: {e}")
            return False
    
    async def _memory_monitor_loop(self):
        """å†…å­˜ç›‘æ§å¾ªç¯ï¼ˆæ¯10ç§’æ£€æŸ¥ï¼‰"""
        while self.running:
            try:
                await asyncio.sleep(10)
                
                mem_usage = self._get_memory_usage_percent()
                queue_size = self.queue.qsize()
                
                if mem_usage > self.config.memory_safe_threshold:
                    logger.warning(f"âš ï¸ å†…å­˜å‹åŠ›é«˜: {mem_usage:.1f}% | é˜Ÿåˆ—: {queue_size}")
                
                if queue_size > self.config.queue_max_size * 0.8:
                    logger.warning(f"âš ï¸ é˜Ÿåˆ—å †ç§¯: {queue_size}/{self.config.queue_max_size}")
                
            except Exception as e:
                logger.error(f"å†…å­˜ç›‘æ§å¼‚å¸¸: {e}")
    
    async def _consumer_loop(self):
        logger.info("ğŸ”„ æ¶ˆè´¹è€…å¾ªç¯å¯åŠ¨ï¼ˆæ‰¹é‡å¤„ç† + å†…å­˜æ„ŸçŸ¥ï¼‰...")
        
        while self.running:
            try:
                queue_item = await asyncio.wait_for(
                    self.queue.get(), 
                    timeout=self.config.processing_timeout
                )
                await self._process_single_item(queue_item)
                self.queue.task_done()
                
            except asyncio.TimeoutError:
                if len(self._step1_buffer) > 0:
                    await self._flush_buffer()
                continue
            except Exception as e:
                logger.error(f"å¾ªç¯å¼‚å¸¸: {e}")
                self.counters['errors'] += 1
                await asyncio.sleep(0.1)
    
    async def _process_single_item(self, item: Dict[str, Any]):
        category = item["category"]
        raw_data = item["data"]
        
        async with self.processing_lock:
            try:
                if category == DataType.MARKET:
                    self._step1_buffer.append(raw_data)
                    
                    if len(self._step1_buffer) >= self.config.batch_size:
                        await self._flush_buffer()
                    
                elif category == DataType.ACCOUNT:
                    await self._process_account_data(raw_data)
                
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥: {raw_data.get('symbol', 'N/A')} - {e}")
                self.counters['errors'] += 1
    
    async def _flush_buffer(self):
        """æ‰¹é‡åˆ·æ–°ç¼“å†²åŒº"""
        if not self._step1_buffer:
            return
        
        try:
            logger.debug(f"æ‰¹é‡å¤„ç† {len(self._step1_buffer)} æ¡æ•°æ®...")
            
            step1_results = self.step1.process(self._step1_buffer)
            self._step1_buffer.clear()
            
            if not step1_results:
                return
            
            step2_results = self.step2.process(step1_results)
            if not step2_results:
                return
            
            step3_results = self.step3.process(step2_results)
            if not step3_results:
                return
            
            step4_results = self.step4.process(step3_results)
            if not step4_results:
                return
            
            final_results = self.step5.process(step4_results)
            if not final_results:
                return
            
            if self.brain_callback:
                for result in final_results:
                    await self.brain_callback(result.__dict__)
            
            self.counters['batches_processed'] += 1
            self.counters['market_processed'] += len(final_results)
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            self.counters['errors'] += 1
    
    async def _process_account_data(self, data: Dict[str, Any]):
        if self.brain_callback:
            await self.brain_callback(data)
        
        self.counters['account_processed'] += 1
        logger.debug(f"ğŸ’° è´¦æˆ·æ•°æ®ç›´è¾¾: {data.get('exchange', 'N/A')}")
    
    def get_status(self) -> Dict[str, Any]:
        uptime = time.time() - self.counters['start_time']
        mem_usage = self._get_memory_usage_percent()
        return {
            "running": self.running,
            "uptime_seconds": uptime,
            "market_processed": self.counters['market_processed'],
            "account_processed": self.counters['account_processed'],
            "batches_processed": self.counters['batches_processed'],
            "errors": self.counters['errors'],
            "queue_size": self.queue.qsize(),
            "buffer_size": len(self._step1_buffer),
            "memory_usage_percent": mem_usage,
            "dropped_due_to_memory": self.counters['dropped_due_to_memory'],
            "memory_safe": self._is_memory_safe()
        }
