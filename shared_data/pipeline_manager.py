"""
PipelineManager è°ƒä¼˜ç‰ˆ - æ‰¹é‡å¤„ç† + èƒŒå‹æ§åˆ¶
åŠŸèƒ½ï¼šéš”10æ¡æ‰¹é‡è·‘ä¸€æ¬¡Step2-5ï¼Œå¤§å¹…é™ä½CPUå¼€é”€
"""

import asyncio
from enum import Enum
from typing import Dict, Any, List, Optional, Callable
from datetime import datetime
import logging
import time
from dataclasses import dataclass

# 5ä¸ªæ­¥éª¤
from shared_data.step1_filter import Step1Filter
from shared_data.step2_fusion import Step2Fusion
from shared_data.step3_align import Step3Align
from shared_data.step4_calc import Step4Calc
from shared_data.step5_cross_calc import Step5CrossCalc

logger = logging.getLogger(__name__)

class DataType(Enum):
    MARKET = "market"
    ACCOUNT = "account"

@dataclass
class PipelineConfig:
    """è°ƒä¼˜ç‰ˆé…ç½®"""
    queue_max_size: int = 1000           # âœ… å¢å¤§åˆ°1000ï¼ˆå†…å­˜ä»ç„¶å®‰å…¨ï¼‰
    processing_timeout: float = 1.0
    batch_size: int = 10                 # âœ… æ–°å¢ï¼šæ¯10æ¡æ‰¹é‡å¤„ç†ä¸€æ¬¡
    log_interval: int = 60

class PipelineManager:
    """è°ƒä¼˜ç‰ˆ - æ‰¹é‡å¤„ç† + ä¿ç•™Step4ç¼“å­˜"""
    
    _instance: Optional['PipelineManager'] = None
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    @classmethod
    def instance(cls) -> 'PipelineManager':
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    def __init__(self, brain_callback: Optional[Callable] = None, 
                 config: Optional[PipelineConfig] = None):
        
        if hasattr(self, '_initialized') and self._initialized:
            return
        
        self.config = config or PipelineConfig()
        self.brain_callback = brain_callback
        
        # 5ä¸ªæ­¥éª¤
        self.step1 = Step1Filter()
        self.step2 = Step2Fusion()
        self.step3 = Step3Align()
        self.step4 = Step4Calc()
        self.step5 = Step5CrossCalc()
        
        self.processing_lock = asyncio.Lock()
        
        self.counters = {
            'market_processed': 0,
            'account_processed': 0,
            'errors': 0,
            'batches_processed': 0,  # âœ… æ–°å¢ï¼šæ‰¹é‡è®¡æ•°
            'start_time': time.time()
        }
        
        self.running = False
        self.queue = asyncio.Queue(maxsize=self.config.queue_max_size)
        
        # âœ… æ–°å¢ï¼šStep1ä¸´æ—¶ç¼“å­˜ï¼ˆæ‰¹é‡å¤„ç†ç”¨ï¼‰
        self._step1_buffer: List[Any] = []
        
        logger.info(f"âœ… è°ƒä¼˜ç‰ˆPipelineManageråˆå§‹åŒ–å®Œæˆ (é˜Ÿåˆ—: {self.config.queue_max_size}, æ‰¹é‡: {self.config.batch_size})")
        self._initialized = True
    
    async def start(self):
        if self.running:
            return
        
        logger.info("ğŸš€ è°ƒä¼˜ç‰ˆPipelineManagerå¯åŠ¨...")
        self.running = True
        
        asyncio.create_task(self._consumer_loop())
        logger.info("âœ… æ¶ˆè´¹è€…å¾ªç¯å·²å¯åŠ¨")
    
    async def stop(self):
        logger.info("ğŸ›‘ PipelineManageråœæ­¢ä¸­...")
        self.running = False
        
        await asyncio.sleep(1)
        
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except:
                break
        
        logger.info("âœ… PipelineManagerå·²åœæ­¢")
    
    async def ingest_data(self, data: Dict[str, Any]) -> bool:
        try:
            data_type = data.get("data_type", "")
            if data_type.startswith(("ticker", "funding_rate", "mark_price",
                                   "okx_", "binance_")):
                category = DataType.MARKET
            elif data_type.startswith(("account", "position", "order", "trade")):
                category = DataType.ACCOUNT
            else:
                category = DataType.MARKET
            
            queue_item = {
                "category": category,
                "data": data,
                "timestamp": time.time()
            }
            
            self.queue.put_nowait(queue_item)
            return True
            
        except asyncio.QueueFull:
            logger.warning(f"âš ï¸ é˜Ÿåˆ—å·²æ»¡ï¼ˆ>{self.config.queue_max_size}ï¼‰ï¼Œæ•°æ®è¢«æ‹’ç»")
            return False
        except Exception as e:
            logger.error(f"å…¥é˜Ÿå¤±è´¥: {e}")
            return False
    
    async def _consumer_loop(self):
        logger.info("ğŸ”„ æ¶ˆè´¹è€…å¾ªç¯å¯åŠ¨ï¼ˆæ‰¹é‡å¤„ç†æ¨¡å¼ï¼‰...")
        
        while self.running:
            try:
                queue_item = await asyncio.wait_for(
                    self.queue.get(), 
                    timeout=self.config.processing_timeout
                )
                await self._process_single_item(queue_item)
                self.queue.task_done()
                
            except asyncio.TimeoutError:
                # âœ… è¶…æ—¶åæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°ç¼“å†²åŒº
                if len(self._step1_buffer) > 0:
                    await self._flush_buffer()
                continue
            except Exception as e:
                logger.error(f"å¾ªç¯å¼‚å¸¸: {e}")
                self.counters['errors'] += 1
                await asyncio.sleep(0.1)
    
    async def _process_single_item(self, item: Dict[str, Any]):
        category = item["category"]
        raw_data = item["data"]
        
        async with self.processing_lock:
            try:
                if category == DataType.MARKET:
                    # âœ… å…ˆç¼“å­˜åˆ°Step1ç¼“å†²åŒº
                    self._step1_buffer.append(raw_data)
                    
                    # âœ… è¾¾åˆ°æ‰¹é‡å¤§å°å†å¤„ç†
                    if len(self._step1_buffer) >= self.config.batch_size:
                        await self._flush_buffer()
                    
                elif category == DataType.ACCOUNT:
                    await self._process_account_data(raw_data)
                
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥: {raw_data.get('symbol', 'N/A')} - {e}")
                self.counters['errors'] += 1
    
    async def _flush_buffer(self):
        """æ‰¹é‡åˆ·æ–°ç¼“å†²åŒº"""
        if not self._step1_buffer:
            return
        
        try:
            logger.debug(f"æ‰¹é‡å¤„ç† {len(self._step1_buffer)} æ¡æ•°æ®...")
            
            # Step1: æ‰¹é‡æå–
            step1_results = self.step1.process(self._step1_buffer)
            self._step1_buffer.clear()  # âœ… ç«‹å³æ¸…ç©ºç¼“å†²åŒº
            
            if not step1_results:
                return
            
            # Step2-5: ç»§ç»­æ‰¹é‡å¤„ç†
            step2_results = self.step2.process(step1_results)
            if not step2_results:
                return
            
            step3_results = self.step3.process(step2_results)
            if not step3_results:
                return
            
            step4_results = self.step4.process(step3_results)
            if not step4_results:
                return
            
            final_results = self.step5.process(step4_results)
            if not final_results:
                return
            
            # æ¨é€å¤§è„‘
            if self.brain_callback:
                for result in final_results:
                    await self.brain_callback(result.__dict__)
            
            self.counters['batches_processed'] += 1
            self.counters['market_processed'] += len(final_results)
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            self.counters['errors'] += 1
    
    async def _process_account_data(self, data: Dict[str, Any]):
        """è´¦æˆ·æ•°æ®ï¼šç›´è¿å¤§è„‘"""
        if self.brain_callback:
            await self.brain_callback(data)
        
        self.counters['account_processed'] += 1
        logger.debug(f"ğŸ’° è´¦æˆ·æ•°æ®ç›´è¾¾: {data.get('exchange', 'N/A')}")
    
    def get_status(self) -> Dict[str, Any]:
        uptime = time.time() - self.counters['start_time']
        return {
            "running": self.running,
            "uptime_seconds": uptime,
            "market_processed": self.counters['market_processed'],
            "account_processed": self.counters['account_processed'],
            "batches_processed": self.counters['batches_processed'],  # âœ… æ‰¹é‡è®¡æ•°
            "errors": self.counters['errors'],
            "queue_size": self.queue.qsize(),
            "buffer_size": len(self._step1_buffer),  # âœ… ç¼“å†²åŒºå½“å‰å¤§å°
            "step4_cache_size": len(self.step4.binance_cache) if hasattr(self.step4, 'binance_cache') else 0
        }
